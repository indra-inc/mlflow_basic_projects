{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Objectives: Detail drive of Model Registry, Staging and Model Serving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Suppress a specific warning by category\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-1: Model Training Life Cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading:\n",
    "def load_data(url):\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(filepath_or_buffer=url,sep=',')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting:\n",
    "def data_split(final_data,target_column):\n",
    "    X = final_data.loc[:, final_data.columns != target_column]\n",
    "    y = final_data.loc[:, final_data.columns == target_column]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify = y, random_state=47)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for Clasification: Logistic Regression\n",
    "def training_basic_classifier(X_train,y_train):\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train,y_train)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_rf_classifier(X_train,y_train):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=101)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for Test Data:\n",
    "def predict_on_test_data(model,X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Probabilty for Test Data: Optional\n",
    "def predict_prob_on_test_data(model,X_test):\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics creation\n",
    "def get_metrics(y_true, y_pred, y_pred_prob):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred,average='micro')\n",
    "    recall = recall_score(y_true, y_pred,average='micro')\n",
    "    entropy = log_loss(y_true, y_pred_prob)\n",
    "    return {'accuracy': round(acc, 2), 'precision': round(prec, 2), 'recall': round(recall, 2), 'entropy': round(entropy, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_confusion_matrix_plot(y_true, y_pred, labels=None, save_path=None):\n",
    "#     # Compute the confusion matrix\n",
    "#     mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#     # Generate labels for the matrix if not provided\n",
    "#     if labels is None:\n",
    "#         labels = range(len(mat))\n",
    "\n",
    "#     # Create a heatmap plot\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.set(font_scale=1.2)  # Adjust the font size\n",
    "#     sns.heatmap(mat, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "#     plt.xlabel('Predicted Labels')\n",
    "#     plt.ylabel('True Labels')\n",
    "#     plt.title('Confusion Matrix')\n",
    "\n",
    "#     # Save the plot if a save_path is provided\n",
    "#     if save_path:\n",
    "#         plt.savefig(save_path, bbox_inches='tight')\n",
    "\n",
    "#     # Display the plot\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "def create_confusion_matrix_plot(y_true, y_pred):\n",
    "    mat = confusion_matrix(y_true, y_pred)\n",
    "    # print(mat)\n",
    "    # plt.show()\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-2: Performing Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0            5.1           3.5            1.4           0.2        0\n",
       "1            4.9           3.0            1.4           0.2        0\n",
       "2            4.7           3.2            1.3           0.2        0\n",
       "3            4.6           3.1            1.5           0.2        0\n",
       "4            5.0           3.6            1.4           0.2        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "url = './Iris.csv'\n",
    "data = load_data(url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "target_column = \"Species\"\n",
    "X_train, X_test, y_train, y_test = data_split(data, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "26             5.0           3.4            1.6           0.4\n",
       "41             4.5           2.3            1.3           0.3\n",
       "49             5.0           3.3            1.4           0.2\n",
       "44             5.1           3.8            1.9           0.4\n",
       "141            6.9           3.1            5.1           2.3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/indra-inc/ML_Doc/mflow_projects/mlflow-env/lib/python3.10/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/media/indra-inc/ML_Doc/mflow_projects/mlflow-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "model = training_basic_classifier(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 2, 2, 1, 2, 1, 1, 2, 1, 2, 0, 0, 2, 0, 1, 1, 1, 1, 2,\n",
       "       2, 0, 0, 2, 1, 0, 1, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 1, 2, 2, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_on_test_data(model,X_test)     # Test data prediction\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.60709889e-01, 3.92891122e-02, 9.98779633e-07],\n",
       "       [9.34702567e-01, 6.52968331e-02, 5.99767945e-07],\n",
       "       [9.70974210e-01, 2.90255308e-02, 2.58847505e-07],\n",
       "       [9.54953581e-01, 4.50439371e-02, 2.48163810e-06],\n",
       "       [1.74813395e-04, 1.07986185e-01, 8.91839001e-01],\n",
       "       [1.59414983e-05, 8.15768455e-02, 9.18407213e-01],\n",
       "       [3.57053116e-03, 7.13593488e-01, 2.82835980e-01],\n",
       "       [4.31196406e-04, 1.90652756e-01, 8.08916047e-01],\n",
       "       [8.32139704e-03, 8.65320067e-01, 1.26358536e-01],\n",
       "       [1.95079123e-02, 8.41162257e-01, 1.39329831e-01],\n",
       "       [2.92676901e-05, 4.04386355e-02, 9.59532097e-01],\n",
       "       [7.76931170e-03, 8.63228862e-01, 1.29001827e-01],\n",
       "       [7.45332011e-04, 3.66637758e-01, 6.32616910e-01],\n",
       "       [9.67661210e-01, 3.23384432e-02, 3.46568517e-07],\n",
       "       [9.77115276e-01, 2.28845278e-02, 1.96720668e-07],\n",
       "       [1.69574652e-07, 8.50651690e-03, 9.91493314e-01],\n",
       "       [9.59223233e-01, 4.07764110e-02, 3.55763420e-07],\n",
       "       [1.76334516e-03, 6.28534148e-01, 3.69702506e-01],\n",
       "       [1.09480025e-02, 7.09625969e-01, 2.79426028e-01],\n",
       "       [7.39475024e-03, 7.51538979e-01, 2.41066271e-01],\n",
       "       [1.24094068e-02, 6.89949703e-01, 2.97640890e-01],\n",
       "       [4.05346526e-04, 2.83006384e-01, 7.16588270e-01],\n",
       "       [1.39493763e-04, 2.39832124e-01, 7.60028383e-01],\n",
       "       [9.68945638e-01, 3.10540005e-02, 3.61157757e-07],\n",
       "       [9.39849558e-01, 6.01480571e-02, 2.38452444e-06],\n",
       "       [5.86429675e-06, 1.59294037e-02, 9.84064732e-01],\n",
       "       [6.49297324e-04, 5.19545624e-01, 4.79805079e-01],\n",
       "       [9.75253426e-01, 2.47463147e-02, 2.58984127e-07],\n",
       "       [1.83975794e-03, 7.42295518e-01, 2.55864724e-01],\n",
       "       [9.33734088e-04, 4.20267053e-01, 5.78799213e-01],\n",
       "       [9.76406924e-01, 2.35927100e-02, 3.65749986e-07],\n",
       "       [8.57315003e-05, 3.81480380e-02, 9.61766231e-01],\n",
       "       [9.85829335e-01, 1.41705031e-02, 1.62022318e-07],\n",
       "       [9.81002991e-01, 1.89967367e-02, 2.72292001e-07],\n",
       "       [9.64717320e-01, 3.52811079e-02, 1.57251858e-06],\n",
       "       [9.61547828e-01, 3.84517119e-02, 4.59755068e-07],\n",
       "       [1.39833811e-05, 2.68080105e-02, 9.73178006e-01],\n",
       "       [7.56969965e-04, 2.31718223e-01, 7.67524807e-01],\n",
       "       [1.56824113e-05, 2.44321080e-02, 9.75552210e-01],\n",
       "       [2.55426034e-02, 9.01565310e-01, 7.28920864e-02],\n",
       "       [4.40211610e-02, 8.86390665e-01, 6.95881737e-02],\n",
       "       [2.31672543e-06, 3.06974477e-02, 9.69300236e-01],\n",
       "       [4.09815129e-05, 1.45972893e-01, 8.53986126e-01],\n",
       "       [2.12569623e-02, 9.38015377e-01, 4.07276612e-02],\n",
       "       [3.96495638e-02, 9.47658184e-01, 1.26922527e-02]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = predict_prob_on_test_data(model,X_test)       # Test Prediction probability\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.93, 'precision': 0.93, 'recall': 0.93, 'entropy': 0.17}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)      # Showing the matrics\n",
    "run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0,  0],\n",
       "       [ 0, 13,  2],\n",
       "       [ 0,  1, 14]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = create_confusion_matrix_plot(y_test, y_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the confusion matrix as a file (e.g., a text file)\n",
    "np.savetxt(\"./confusion_matrix.txt\", conf_mat, fmt='%d', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-3: Create Experiment for Mlflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name,run_name,model_name, run_metrics,model, confusion_matrix_path = None, \n",
    "                    run_params=None):\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\") \n",
    "    #use above line if you want to use any database like sqlite as backend storage for model else comment this line\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "            \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric, run_metrics[metric])\n",
    "        \n",
    "        \n",
    "        if not confusion_matrix_path == None:\n",
    "            mlflow.log_artifact(confusion_matrix_path, 'confusion_matrix')\n",
    "            # Log the confusion matrix file as an artifact\n",
    "            # mlflow.log_artifact(\"confusion_matrix.txt\", artifact_path=\"your_artifact_path\")\n",
    "        \n",
    "        mlflow.set_tag(\"Model\", model_name)\n",
    "        mlflow.set_tags({\"Developers\":\"Indra-Inc\", \"Classification Type\":\"Multiclassification\"})\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "    print('Run - %s is logged to Experiment - %s' %(run_name, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-4: Start Mlflow Server\n",
    "- We will use SQLite as backend so run it on CLI: mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 --port 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/10 23:02:25 INFO mlflow.tracking.fluent: Experiment with name 'Iris_Classifier_10-09-23' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - iris_classifier_10-09-23 is logged to Experiment - Iris_Classifier_10-09-23\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "experiment_name = \"Iris_Classifier_\"+ str(datetime.now().strftime(\"%d-%m-%y\")) ##basic classifier\n",
    "run_name=\"iris_classifier_\"+str(datetime.now().strftime(\"%d-%m-%y\"))\n",
    "model_name = \"Logistic_without_Optimization\"\n",
    "create_experiment(experiment_name,run_name, model_name, run_metrics,model,'confusion_matrix.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 2, 2, 1, 2, 1, 1, 2, 1, 2, 0, 0, 2, 0, 1, 1, 1, 1, 2,\n",
       "       2, 0, 0, 2, 1, 0, 1, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 1, 2, 2, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now from mlflow artifact section copy paste the code and execute it to check the prediction\n",
    "\n",
    "logged_model = 'runs:/1dfd4459ba49408fbedf735b884e3608/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pdi\n",
    "loaded_model.predict(pd.DataFrame(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_2: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/indra-inc/ML_Doc/mflow_projects/mlflow-env/lib/python3.10/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_rf = training_rf_classifier(X_train,y_train)\n",
    "y_pred_rf = predict_on_test_data(model_rf,X_test)\n",
    "y_pred_prob_rf = predict_prob_on_test_data(model_rf,X_test)\n",
    "run_metrics_rf = get_metrics(y_test, y_pred_rf, y_pred_prob_rf)\n",
    "conf_mat_rf = create_confusion_matrix_plot(y_test, y_pred_rf)\n",
    "np.savetxt(\"./confusion_matrix_rf.txt\", conf_mat_rf, fmt='%d', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-5: Mlflow Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method-1: mlflow.<model_flavor e.g here sklearn>.log_model()\n",
    "- ```\n",
    "    # Log the sklearn model and register as version 1\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"sklearn-model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=\"sk-learn-random-forest-reg-model\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_exp_and_register_model(experiment_name,run_name,model_name, run_metrics,model, confusion_matrix_path = None, run_params=None):\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\") \n",
    "    #use above line if you want to use any database like sqlite as backend storage for model else comment this line\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "            \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric, run_metrics[metric])\n",
    "        \n",
    "        \n",
    "        if not confusion_matrix_path == None:\n",
    "            mlflow.log_artifact(confusion_matrix_path, 'confusion_matrix')\n",
    "        \n",
    "        mlflow.set_tag(\"Model\", model_name)\n",
    "        mlflow.set_tags({\"Developers\":\"Indra-Inc\", \"Classification Type\":\"Multiclassification\"})\n",
    "        mlflow.sklearn.log_model(model, \"model\",registered_model_name=\"iris-classifier-rf\")\n",
    "    print('Run - %s is logged to Experiment - %s' %(run_name, experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'iris-classifier-rf'.\n",
      "2023/09/10 23:06:11 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: iris-classifier-rf, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - iris_classifier_rf_method-1_10-09-23 is logged to Experiment - Iris_Classifier_10-09-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'iris-classifier-rf'.\n"
     ]
    }
   ],
   "source": [
    "# experiment_name = \"iris_classifier_rf_method-1_\" + str(datetime.now().strftime(\"%d-%m-%y\")) ## random forest classifier\n",
    "run_name=\"iris_classifier_rf_method-1_\" +str(datetime.now().strftime(\"%d-%m-%y\"))\n",
    "model_name_rf = \"Random_Forest_without_Optimization\"\n",
    "create_exp_and_register_model(experiment_name,run_name, model_name_rf, run_metrics_rf,model_rf,'confusion_matrix_rf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method-2: mlflow.register_model()\n",
    "-  mlflow.register_model() method, after all your experiment runs complete and when you have decided which model is most suitable to add to the registry. For this method, you will need the run_id as part of the runs:URI argument.\n",
    "- `result = mlflow.register_model(\n",
    "    \"runs:/d16076a3ec534311817565e6527539c0/sklearn-model\", \"sk-learn-random-forest-reg\"\n",
    ")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'iris-classifier-lr-1'.\n",
      "2023/09/11 00:02:18 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: iris-classifier-lr-1, version 1\n",
      "Created version '1' of model 'iris-classifier-lr-1'.\n"
     ]
    }
   ],
   "source": [
    "# with mlflow.start_run(run_name=run_name) as run:\n",
    "result = mlflow.register_model(\n",
    "        \"runs:/1dfd4459ba49408fbedf735b884e3608/model\",\n",
    "        \"iris-classifier-lr-1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-6: Fetching Mlflow Model from the Model Registry\n",
    "- As now we have the models in our Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Specific Model Version: As i am taking first model i.e. Logistic Regression Classifier\n",
    "\n",
    "model_name = \"iris-classifier-lr-1\"\n",
    "model_version = 1\n",
    "\n",
    "model_reg_lr_1 = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 2, 2, 1, 2, 1, 1, 2, 1, 2, 0, 0, 2, 0, 1, 1, 1, 1, 2,\n",
       "       2, 0, 0, 2, 1, 0, 1, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 1, 2, 2, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_reg_lr_1.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To see the prediction probability\n",
    "# sklearn_model = mlflow.sklearn.load_model(\n",
    "#     model_uri=f\"models:/{model_name}/{model_version}\"\n",
    "# )\n",
    "# y_pred_prob = sklearn_model.predict_proba(X_test)\n",
    "# print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-7: Transition model into Staging area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1694367371512, current_stage='Staging', description='', last_updated_timestamp=1694373571496, name='iris-classifier-rf', run_id='907b4fded771424ea6403845fad2f492', run_link='', source='/media/indra-inc/ML_Doc/mflow_projects/basic_model_serving_1/artifacts/1/907b4fded771424ea6403845fad2f492/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Staging the RF model into Stage\n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"iris-classifier-rf\", version=1, stage=\"Staging\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1694370738140, current_stage='Production', description='', last_updated_timestamp=1694373578156, name='iris-classifier-lr-1', run_id='1dfd4459ba49408fbedf735b884e3608', run_link='', source='/media/indra-inc/ML_Doc/mflow_projects/basic_model_serving_1/artifacts/1/1dfd4459ba49408fbedf735b884e3608/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Staging the LR model into Production\n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"iris-classifier-lr-1\", version=1, stage=\"Production\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Specific Model Version from Production Staging area\n",
    "\n",
    "model_name = \"iris-classifier-lr-1\"\n",
    "stage = \"Production\"\n",
    "\n",
    "model_prod_lr_1 = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 2, 2, 1, 2, 1, 1, 2, 1, 2, 0, 0, 2, 0, 1, 1, 1, 1, 2,\n",
       "       2, 0, 0, 2, 1, 0, 1, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 1, 2, 2, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prediction for Batched Data\n",
    "y_pred = model_prod_lr_1.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for Single data from Staging area for RF model\n",
    "model_name = \"iris-classifier-rf\"\n",
    "stage = 'Staging'\n",
    "\n",
    "model_stg_rf = mlflow.sklearn.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/indra-inc/ML_Doc/mflow_projects/mlflow-env/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_stg_rf.predict([[6.7,3.3,5.7,2.1]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-8: Serving Mlflow model from Model Registry\n",
    "- mlflow.set_tracking_uri('http://localhost:5000')\n",
    "#### To Set environment variable for the tracking URL where the Model Registry resides\n",
    "- Run this from CLI `set MLFLOW_TRACKING_URI=http://localhost:5000` for Windows `export MLFLOW_TRACKING_URI=http://localhost:5000 ` for Linux\n",
    "#### To Serve the production model from the model registry\n",
    "- mlflow models serve --model-uri models:/iris-classifier-lr-1/Production -p 1234 --no-conda\n",
    "or\n",
    "- mlflow models serve -m \"models:/iris-classifier-lr-1/Production\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Single Data Prediction\n",
    "\n",
    "# import requests\n",
    "\n",
    "# inference_request = {\n",
    "#         \"dataframe_records\": [[6.7,3.3,5.7,2.1]]\n",
    "# }\n",
    "\n",
    "# endpoint = \"http://localhost:1234/prediction\"\n",
    "\n",
    "# response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Batch Prediction\n",
    "# lst = X_test.values.tolist()\n",
    "# inference_request = {\n",
    "#         \"dataframe_records\": lst\n",
    "# }\n",
    "\n",
    "# endpoint = \"http://localhost:1234/prediction\"\n",
    "\n",
    "# response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
